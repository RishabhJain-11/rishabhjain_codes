# -*- coding: utf-8 -*-
"""Fake_News_Prediction_System.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kaWyZhEqFjY5zJv-jxV3RTwsnX6O99TO
"""

# Installing the kaggle library
!pip install kaggle

"""Upload Kaggle.json file

Configuring the path of the json file
"""

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

"""Import the dataset
\
"""

!kaggle competitions download -c fake-news

from zipfile import ZipFile
dataset = '/content/fake-news.zip'

with ZipFile(dataset, 'r') as zip:
  zip.extractall()
  print("The data is extracted")

import numpy as np
import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.porter import PorterStemmer
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

nltk.download('stopwords')

data = pd.read_csv("/content/train.csv")
data.head()

data.isnull().sum()

dataset = data.fillna("")

# prompt: merging the author and title

dataset['content'] = dataset['author'] + " " + dataset['title']

# prompt: seperate the content and data

X = dataset.drop('label', axis=1)
y = dataset['label']

port_stem = PorterStemmer()
def stemming(content):
  stemmed_content = re.sub('[^a-zA-Z]', ' ', content)
  stemmed_content = stemmed_content.lower()
  stemmed_content = stemmed_content.split()
  stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')]
  stemmed_content = ' '.join(stemmed_content)
  return stemmed_content

# prompt: put it into the content column

dataset['content'] = dataset['content'].apply(stemming)

X = dataset['content'].values
y = dataset['label'].values
print(y)

vectorizer = TfidfVectorizer()
vectorizer.fit(X)
X = vectorizer.transform(X)
print(X)

# prompt: apply train test split

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# prompt: show the shape of all train and test

print("X_train shape:", X_train.shape)
print("y_train shape:", y_train.shape)
print("X_test shape:", X_test.shape)
print("y_test shape:", y_test.shape)

# prompt: train the logostic regression model

model = LogisticRegression()
model.fit(X_train, y_train)

# prompt: find the accuracy score on the taining data

y_pred = model.predict(X_train)
accuracy = accuracy_score(y_train, y_pred)
print("Accuracy score on the training data:", accuracy)

# prompt: accuracy score on test data

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy score on the test data:", accuracy)

# prompt: build a predictive system on an example from the news data

# Predicting on a sample news article
# sample_news = "The government has announced a new policy that will provide free healthcare to all citizens."
# sample_news = stemming(sample_news)
# sample_news = vectorizer.transform([sample_news])
# prediction = model.predict(sample_news)
X_new = X_test[32]
prediction = model.predict(X_new)
print(prediction)
if prediction == 1:
  print("The news is fake.")
else:
  print("The news is real.")